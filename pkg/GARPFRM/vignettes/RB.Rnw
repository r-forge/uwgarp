\documentclass[a4paper]{article}
\usepackage[OT1]{fontenc}
\usepackage{Sweave}
\usepackage{Rd}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{url}
\usepackage[round]{natbib}
\usepackage{bm}
\usepackage{verbatim}
\usepackage[latin1]{inputenc}
\bibliographystyle{abbrvnat}

\let\proglang=\textsf
%\newcommand{\pkg}[1]{{\fontseries{b}\selectfont #1}}
%\newcommand{\R}[1]{{\fontseries{b}\selectfont #1}}
%\newcommand{\email}[1]{\href{mailto:#1}{\normalfont\texttt{#1}}}
%\newcommand{\E}{\mathsf{E}}
%\newcommand{\VAR}{\mathsf{VAR}}
%\newcommand{\COV}{\mathsf{COV}}
%\newcommand{\Prob}{\mathsf{P}}

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\renewcommand{\baselinestretch}{1.5}
\setlength{\textwidth}{15cm} \setlength{\textheight}{22cm} \topmargin-1cm \evensidemargin0.5cm \oddsidemargin0.5cm

\usepackage[latin1]{inputenc}
% or whatever

\usepackage{lmodern}
\usepackage[T1]{fontenc}
% Or whatever. Note that the encoding and the font should match. If T1
% does not look nice, try deleting the line with the fontenc.

\begin{document}

\title{Quantitative Analysis}
\author{Ross Bennett}

\maketitle

\begin{abstract}
The goal of this vignette is to demonstrate key concepts in Financial Risk Manager (FRM \textsuperscript{\textregistered}) Part 1: Quantitative Analysis using R and the GARPFRM package. This vignette will cover exploratory data analysis, basic probability and statistics, and linear regression.
\end{abstract}

\tableofcontents

\section{Exploratory Data Analysis}

Load the GARPFRM package and the \verb"returns" dataset. The lattice package is also loaded for plotting functions. The \verb"returns" dataset includes weekly returns for SPY, AAPL, XOM, GOOG, MSFT, and GE from 2005-01-14 to 2013-11-22.
<<>>=
suppressMessages(library(GARPFRM))
suppressMessages(library(lattice))
suppressMessages(library(pcaPP))
data(returns)

# Get the names of the stocks and view the first 5 rows of returns
colnames(returns)
head(returns, 5)
@

Plot of the weekly returns of each asset.
<<>>=
xyplot(returns, scale=list(y="same"), main="Weekly Returns")
@

Another way to compare returns of several assets is with a boxplot.
<<>>=
boxplot(coredata(returns), pch=20, main="Weekly Returns")
@

The exploratory data analysis, basic probability and statistics will use the SPY weekly returns.
<<>>=
# Extract the column labeled "SPY" to get the SPY returns
SPY.ret <- returns[, "SPY"]
@


Plot of the SPY weekly returns. 
<<>>=
plot(SPY.ret, main="SPY Weekly Returns")
@

A histogram and kernel density estimate of the SPY weekly returns is plotted to better understand its distribution. 
<<tidy=FALSE>>=
hist(SPY.ret, probability=TRUE, main="Histogram of SPY Returns", 
     ylim=c(0, 25), col="lightblue")
lines(density(SPY.ret), lty=2)
rug(SPY.ret)
legend("topleft", legend="kernel density estimate", lty=2,
       cex=0.8, bty="n")
@


A normal density is overlayed on the plot with standard estimates of the sample mean and standard deviation. Another normal density is overlayed using robust estimates. It is clear from the chart that the robust estimates provide a better fit than the standard estimates of the sample mean and sample standard deviation, but it is not clear if the SPY returns are normally distributed.
<<>>=
# Plot the kernel density estimate of SPY Weekly Returns
plot(density(SPY.ret), main="Density of SPY Weekly Returns")
rug(SPY.ret)
# sample estimates
curve(dnorm(x, mean=mean(SPY.ret), sd=sd(SPY.ret)), 
      add=TRUE, col="red", lty=2, lwd=2)
# robust estimates
curve(dnorm(x, mean=median(SPY.ret), sd=mad(SPY.ret)), 
      add=TRUE, col="blue", lty=2, lwd=2)
legend("topleft", legend=c("ernel density estimate", "normal density estimate", 
                           "robust normal density estimate"), 
       col=c("black", "red", "blue"), lty=c(1, 2, 2), bty="n", cex=0.8)
@

Quantile-Quantile plot of SPY weekly returns with a 95\% confidence envelope. It can be seen from the Normal Q-Q plot that the tails of the SPY returns are well outside of the 95\% confidence envelope.
<<tidy=FALSE>>=
chart.QQPlot(SPY.ret, envelope=0.95, pch=18, main="SPY Weekly Returns QQ Plot",
             xlab="Theoretical Normal Quantiles")
legend("topleft", legend=c("Quartile-Pairs Line", "95% Confidence Envelope"), 
       col=c("blue", "blue"), lty=c(1, 2), cex=0.8, bty="n")
@

We can test if the SPY weekly returns came from a normal distribution using the Shapiro-Wilk test of normality. The null hypothesis is that the data came from a normal distribution. The p-value is very small and we can reject the null hypothesis.
<<>>=
shapiro.test(coredata(SPY.ret))
@

\subsection{Basic Statistics}
Here we calculate some basic statisitics on the SPY weekly returns.
<<>>=
# Sample mean of SPY return
mean(SPY.ret)

# Sample Variance of SPY returns
var(SPY.ret)

# Sample standard deviation of SPY returns
sd(SPY.ret)

# Standard error of SPY returns
sd(SPY.ret) / sqrt(nrow(SPY.ret))

# Sample skewness of SPY returns.
# See ?skewness for additional methods for calculating skewness
skewness(SPY.ret, method="sample")

# Sample kurtosis of SPY returns.
# See ?kurtosis for additional methods for calculating kurtosis
kurtosis(SPY.ret, method="sample")

# Summary statistics of SPY returns
summary(SPY.ret)

# Sample quantiles of SPY returns
quantile(SPY.ret, probs=c(0, 0.25, 0.5, 0.75, 1))

@

Scatter plot of each pair of assets in the returns dataset.
<<tidy=FALSE>>=
pairs(coredata(returns), pch=20, 
      col=rgb(0,0,100,50,maxColorValue=255))

@

Correlation and covariance matrices of assets in the returns dataset.
<<>>=
# Sample correlation of returns
cor(returns)
@

<<echo=FALSE>>=
suppressWarnings(plotcov(cor(returns), method1="Sample Correlation Estimate"))
@

<<>>=
# Sample covariance of returns
cov(returns)
@

<<echo=FALSE>>=
suppressWarnings(plotcov(cov(returns), method1="Sample Covariance Estimate"))
@


\subsection{Distributions}
R has functions to compute the density, distribution function, quantile, and random number generation for several distributions. The continuous distributions covered in chapter 1 are listed here.
\begin{itemize}
\item Normal Distribution: \verb"dnorm", \verb"pnorm", \verb"qnorm", \verb"rnorm"

\item Chi-Squared Distribution: \verb"dchisq", \verb"pchisq", \verb"qchisq", \verb"rchisq"

\item Student t Distribution: \verb"dt", \verb"pt", \verb"qt", \verb"rt"

\item F Distribution: \verb"df", \verb"pf", \verb"qf", \verb"rf"
\end{itemize}

In general, the functions are as follows:
\begin{itemize}
\item d*: density
\item p*: distribution function (probability)
\item q*: quantile function
\item r*: random generation
\end{itemize}
where * is the appropriate distribution.

Here we demonstrate these functions for the normal distribution.

Use dnorm to plot the pdf of a standard normal distribution
<<>>=
curve(dnorm(x), from=-4, to=4, main="Standard Normal pdf")
@

Calculate the probability that $Y \leq 2$ when $Y$ is distributed $N(1, 4)$ with mean of 1 and variance of 4.
<<>>=
pnorm(q=2, mean=1, sd=2)
# Normalize as is done in the book
pnorm(q=0.5)
@

Quantile function of the standard normal distribution at probability 0.975.
<<>>=
qnorm(p=0.975)
@

Generate 10 random numbers from a normal distribution with mean 0.0015 and standard deviation 0.025.
<<>>=
# Set the seed for reproducible results
set.seed(123)
rnorm(n=10, mean=0.0015, sd=0.025)
@

\subsection{Hypothesis Test}
The null hypothesis is that the true mean return of SPY is equal to 0
<<>>=
t.test(x=SPY.ret, alternative="two.sided", mu=0)

# Replicate the results of t.test using the method outlined in the book
t_stat <- (mean(SPY.ret) - 0) / (sd(SPY.ret) / sqrt(nrow(SPY.ret)))
p_value <- 2 * pt(q=-abs(t_stat), df=462)
df <- nrow(SPY.ret) - 1
ci <- mean(SPY.ret) + c(-1, 1) * 1.96 * sd(SPY.ret) / sqrt(nrow(SPY.ret))
paste("t = ", round(t_stat, 4), ", df = ", df, ", p-value = ", round(p_value, 4), sep="")
print("95% Confidence Interval")
print(ci)
@

\section{Regression}
\subsection{Regression with a single regressor}

Extract the weekly returns of AAPL and SPY from the returns object. The returns of AAPL and SPY will be used to demonstrate linear regression in R.
<<>>=
AAPL.ret <- returns[, "AAPL"]
SPY.ret <- returns[, "SPY"]

# Fitting linear models works with xts objects, but works better with data.frame objects. This is especially true with the predict method for linear models.
ret.data <- as.data.frame(cbind(AAPL.ret, SPY.ret))
@

Scatterplot of AAPL and SPY returns.
<<>>=
plot(coredata(SPY.ret), coredata(AAPL.ret), pch=19,
     col=rgb(0,0,100,50,maxColorValue=255),
     xlab="SPY returns", ylab="AAPL returns")
@

Fit the linear regression model. \verb"AAPL.ret" is the response variable and \verb"SPY.ret" is the explanatory variable.
<<>>=
model.fit <- lm(AAPL ~ SPY, data=ret.data)
@

The \verb"print" and \verb"summary" methods for \verb"lm" objects are very useful and provide several of the statistics covered in the book. Note that \verb"summary(model.fit)" will print the summary statisitcs, but it is often useful to assign the summary object to a variable so that elements from the summary object can be extracted as shown below.
<<>>=
# The print method displays the call and the coefficients of the linear model
model.fit

# The summary method displays additional information for the linear model
model.summary <- summary(model.fit)
model.summary
@

Access elements of the \verb"lm" object
<<>>=
# Coefficients
coef(model.fit)
# Extract the fitted values
# fitted(model.fit)
# Extract the residuals
# resid(model.fit)
# Exctract the standardized residuals
# rstandard(model.fit)
@

Access elements of the \verb"lm.summary" object
<<>>=
# Coefficients
coef(model.summary)
# Sigma
model.summary$sigma
# R squared
model.summary$r.squared
# Adjusted R squared
model.summary$adj.r.squared
@

Use the \verb"predict" method to calculate the confidence and prediction intervals of the fitted model.
<<>>=
new <- data.frame(SPY=seq(from=-0.2, to=0.2, length.out=nrow(ret.data)))
model.ci <- predict(object=model.fit, newdata=new, interval="confidence")
model.pi <- predict(object=model.fit, newdata=new, interval="prediction")
@

Plot the residuals of the model.
<<>>=
plot(resid(model.fit), type="h")
@

Plot the fitted model with the confidence and prediction intervals.
<<tidy=FALSE>>=
plot(coredata(SPY.ret), coredata(AAPL.ret),
     col=rgb(0,0,100,50,maxColorValue=255), pch=20,
     xlab="SPY returns", ylab="AAPL returns", xlim=c(-0.2, 0.2))
abline(model.fit, col="black")
lines(x=model.ci[, "fit"], y=model.ci[, "upr"], col="blue", lty=1)
lines(x=model.ci[, "fit"], y=model.ci[, "lwr"], col="blue", lty=1)
lines(x=model.pi[, "fit"], y=model.pi[, "upr"], col="red", lty=2)
lines(x=model.pi[, "fit"], y=model.pi[, "lwr"], col="red", lty=2)
legend("topleft", legend=c("Fitted Values",
                           "95% Confidence Interval", 
                           "95% Prediction Interval"), 
       col=c("black", "blue", "red"), lty=c(1, 1, 2), cex=0.8, bty="n")
@

\subsection{Regression with multiple regressors}
The Fama French 3 Factor model is used to demonstrate regression with multiple regressors. The first example will use AAPL weekly returns and the Fama French factors from 2005-01-14 to 2013-10-25. The premise of the model is that AAPL returns can be explained by the 3 factors of the Fama French model.

<<>>=
data(fama_french_factors)

# The first 3 columns are the factors, the 4th column is the risk free rate.
ff_factors <- fama_french_factors[, 1:3]
head(ff_factors, 5)
@

Mkt-RF is the market excess return.
SMB is \textbf{S}mall \textbf{M}inus \textbf{B}ig in terms of market capitalization.
HML is \textbf{H}igh \textbf{M}inus \textbf{L}ow in terms of book-to-market.

<<>>=
# Align the dates of the Fama-French Factors and the returns
returns <- returns['/2013-10-25']
AAPL.ret <- returns[, "AAPL"]

# AAPL excess returns
AAPL.e <- AAPL.ret - fama_french_factors[, "RF"] / 100
@

<<>>=
# Fit the model
ff.fit <- lm(AAPL.e ~ ff_factors)
ff.fit
summary(ff.fit)
@

If we wanted to fit the model to more assets, we could manually fit the model with different assets as the response variable. However, we can automatically fit several models very easily with R.

<<>>=
# Omit the first column of returns because it is the SPY weekly returns, which is
# a proxy for the market.
returns <- returns[, -1]

# Calculate the excess returns of all assets in the returns object
ret.e <- returns - (fama_french_factors[, "RF"] / 100) %*% rep(1, ncol(returns))
@

The \verb"ret.e" object contains the excess returns for AAPL, XOM, GOOG, MSFT, and GE.
<<>>=
# Show the first 5 rows of ret.e
head(ret.e, 5)
@

Here we fit the Fama French 3 Factor model to each asset in \verb"ret.e". This fits 5 models, 1 for each asset, and stores results of each model in the \verb"ff.fit" object as a multiple linear model (mlm) object.
<<>>=
ff.fit <- lm(ret.e ~ ff_factors)
# Display the coefficients of each model
ff.fit
@

Extract and plot the beta values and the R squared values for each asset from the Fama French 3 Factor model.
<<>>=
beta0 <- coef(ff.fit)[1,]
beta1 <- coef(ff.fit)[2,]
beta2 <- coef(ff.fit)[3,]
beta3 <- coef(ff.fit)[4,]
rsq <- sapply(X=summary(ff.fit), FUN=function(x) x$r.squared)
names(rsq) <- colnames(ret.e)

par(mfrow=c(2,2))
barplot(beta1, main="Beta for Market-RF", col=c(2:6), cex.names=0.8)
barplot(beta2, main="Beta for SMB", col=c(2:6), cex.names=0.8)
barplot(beta3, main="Beta for HML", col=c(2:6), cex.names=0.8)
barplot(rsq, main="R Squared Values", col=c(2:6), cex.names=0.8)
par(mfrow=c(1,1))
@

Display the summary object for each model
<<>>=
summary(ff.fit)
@


\end{document}